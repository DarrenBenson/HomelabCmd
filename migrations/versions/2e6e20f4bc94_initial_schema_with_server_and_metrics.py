"""Initial schema with Server and Metrics

Revision ID: 2e6e20f4bc94
Revises:
Create Date: 2026-01-18 18:58:11.999824

"""

from collections.abc import Sequence

import sqlalchemy as sa
from alembic import op

# revision identifiers, used by Alembic.
revision: str = "2e6e20f4bc94"
down_revision: str | Sequence[str] | None = None
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "servers",
        sa.Column("id", sa.String(length=100), nullable=False),
        sa.Column("hostname", sa.String(length=255), nullable=False),
        sa.Column("display_name", sa.String(length=255), nullable=True),
        sa.Column("ip_address", sa.String(length=45), nullable=True),
        sa.Column("status", sa.String(length=20), nullable=False),
        sa.Column("os_distribution", sa.String(length=100), nullable=True),
        sa.Column("os_version", sa.String(length=100), nullable=True),
        sa.Column("kernel_version", sa.String(length=100), nullable=True),
        sa.Column("architecture", sa.String(length=20), nullable=True),
        sa.Column("tdp_watts", sa.Integer(), nullable=True),
        sa.Column("last_seen", sa.DateTime(timezone=True), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "metrics",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("server_id", sa.String(length=100), nullable=False),
        sa.Column("timestamp", sa.DateTime(timezone=True), nullable=False),
        sa.Column("cpu_percent", sa.Float(), nullable=True),
        sa.Column("memory_percent", sa.Float(), nullable=True),
        sa.Column("memory_total_mb", sa.Integer(), nullable=True),
        sa.Column("memory_used_mb", sa.Integer(), nullable=True),
        sa.Column("disk_percent", sa.Float(), nullable=True),
        sa.Column("disk_total_gb", sa.Float(), nullable=True),
        sa.Column("disk_used_gb", sa.Float(), nullable=True),
        sa.Column("network_rx_bytes", sa.BigInteger(), nullable=True),
        sa.Column("network_tx_bytes", sa.BigInteger(), nullable=True),
        sa.Column("load_1m", sa.Float(), nullable=True),
        sa.Column("load_5m", sa.Float(), nullable=True),
        sa.Column("load_15m", sa.Float(), nullable=True),
        sa.Column("uptime_seconds", sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(["server_id"], ["servers.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("metrics", schema=None) as batch_op:
        batch_op.create_index(
            "idx_metrics_server_timestamp", ["server_id", "timestamp"], unique=False
        )
        batch_op.create_index(batch_op.f("ix_metrics_server_id"), ["server_id"], unique=False)
        batch_op.create_index(batch_op.f("ix_metrics_timestamp"), ["timestamp"], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("metrics", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_metrics_timestamp"))
        batch_op.drop_index(batch_op.f("ix_metrics_server_id"))
        batch_op.drop_index("idx_metrics_server_timestamp")

    op.drop_table("metrics")
    op.drop_table("servers")
    # ### end Alembic commands ###
